{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_0EAtT55CLA"
      },
      "source": [
        "## 1. Build a ChatBot pipeline Using Hugging Face Transformers Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8yLdPtP5MGz"
      },
      "source": [
        "Install the transformers library and import the pipeline method to use the open source models also add an additional library to avoid warnings message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH2seTTM4zs3",
        "outputId": "bfb7fd87-4f0a-476b-8455-ab3551c30ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n"
          ]
        }
      ],
      "source": [
        "!pip intall transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YlE9VrR74zvf"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from transformers.utils import logging\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaduyiRA5KCf"
      },
      "source": [
        "The conversation pipeline is a sequence of tasks executed using the **`pipeline()`** method from the Transformers library. To create a pipeline, first define the task, then specify the model. When **`pipeline()`** is called with these parameters, it creates an object that can analyze text and perform sentiment analysis using the chosen model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-PS2bFSb4zx_"
      },
      "outputs": [],
      "source": [
        "chatbot = pipeline(task=\"conversational\",\n",
        "                   model=\"facebook/blenderbot-400M-distill\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A1krGZ85lvZ"
      },
      "source": [
        "Info about ['blenderbot-400M-distill'](https://huggingface.co/facebook/blenderbot-400M-distill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IvLJ9RWM4z0P"
      },
      "outputs": [],
      "source": [
        "user_message = \"\"\"\n",
        "Suggest me some good project ideas on machine learning?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "t4hA7K8Z5ucr"
      },
      "outputs": [],
      "source": [
        "from transformers import Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RvXkZ6Gd5w3b"
      },
      "outputs": [],
      "source": [
        "conversation = Conversation(user_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3pCS1MN5xBw",
        "outputId": "7d7ec940-e3fa-4f93-eb4b-8b2f871445d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oVdeBFmE5yDA"
      },
      "outputs": [],
      "source": [
        "conversation = chatbot(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEzZYHqu50gi",
        "outputId": "c8796a76-2498-49bd-d193-e1b0beedb781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "assistant:  I'm not sure, but I do know that machines are used in many fields of science and technology.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfvqu1zH5408"
      },
      "source": [
        "- To resume the conversation with the chatbot, use the following code:\n",
        "```\n",
        "print(chatbot(Conversation(\"What else do you recommend?\")))\n",
        "```\n",
        "- Keep in mind that the chatbot might give an unrelated response because it doesn't remember any previous conversations.\n",
        "\n",
        "- If you want to include previous conversations in the Large Language Model's (LLM) context, you can add a 'message' to incorporate the chat history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "kOXHMbaM58uQ"
      },
      "outputs": [],
      "source": [
        "conversation.add_message(\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"\"\"\n",
        "What else do you recommend?\n",
        "\"\"\"\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTWAkqWT6AU2",
        "outputId": "740fc683-5926-4286-f486-0226440a6699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "assistant:  I'm not sure, but I do know that machines are used in many fields of science and technology.\n",
            "user: \n",
            "What else do you recommend?\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5wz-90G6BUg",
        "outputId": "71e2b69f-7ec1-4618-8bf1-763785002d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "assistant:  I'm not sure, but I do know that machines are used in many fields of science and technology.\n",
            "user: \n",
            "What else do you recommend?\n",
            "\n",
            "assistant:  Well, I know that there are many different types of machines that can be used. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "conversation = chatbot(conversation)\n",
        "print(conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4neJjYD6JHA"
      },
      "source": [
        "- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
        "- [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cay_63c86N5O"
      },
      "source": [
        "## 2. Translation and Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "fPKJ42bI6CYO"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NRLeedp56Xua"
      },
      "outputs": [],
      "source": [
        "translator = pipeline(task=\"translation\",\n",
        "                      model=\"facebook/nllb-200-distilled-600M\",\n",
        "                      torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UzA2h0n6bg7"
      },
      "source": [
        "NLLB: No Language Left Behind: ['nllb-200-distilled-600M'](https://huggingface.co/facebook/nllb-200-distilled-600M). <br>\n",
        "This model is capable of translating 200 languages. By setting the dtype to BFloat16 we are able to compress the model without any performance degradation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8ondz0B76Z3s"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\\\n",
        "My pet is adorable, \\\n",
        "Your pet is cute.\n",
        "Her pet is friendly.\n",
        "His pet is thoughtful. \\\n",
        "We all have nice pets!\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cDIUqZ984fV"
      },
      "source": [
        "After creating the pipeline object, we can provide the text for translation. We specify the source language (English) and the target language (French) for the translation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hE-Fz2Ha6iU7"
      },
      "outputs": [],
      "source": [
        "text_translated = translator(text,\n",
        "                             src_lang=\"eng_Latn\",\n",
        "                             tgt_lang=\"fra_Latn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0IbIjKU6myb"
      },
      "source": [
        "To choose other languages, you can find the other language codes on the page: [Languages in FLORES-200](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n",
        "\n",
        "For example:\n",
        "- Afrikaans: afr_Latn\n",
        "- Chinese: zho_Hans\n",
        "- Egyptian Arabic: arz_Arab\n",
        "- French: fra_Latn\n",
        "- German: deu_Latn\n",
        "- Greek: ell_Grek\n",
        "- Hindi: hin_Deva\n",
        "- Indonesian: ind_Latn\n",
        "- Italian: ita_Latn\n",
        "- Japanese: jpn_Jpan\n",
        "- Korean: kor_Hang\n",
        "- Persian: pes_Arab\n",
        "- Portuguese: por_Latn\n",
        "- Russian: rus_Cyrl\n",
        "- Spanish: spa_Latn\n",
        "- Swahili: swh_Latn\n",
        "- Thai: tha_Thai\n",
        "- Turkish: tur_Latn\n",
        "- Vietnamese: vie_Latn\n",
        "- Zulu: zul_Latn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2ObFLt36k_U",
        "outputId": "53f97e89-f214-4f22-efd0-43f94c1fed57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'Mon animal est adorable, ton animal est mignon, son animal est ami, son animal est attentionné, nous avons tous de beaux animaux.'}]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_translated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WifcoTQ6qHX"
      },
      "source": [
        "### Free up some space\n",
        "In order to have enough free memory to run the rest of the code, please run the following to free up memory on the machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKI9mJjw6oaC",
        "outputId": "8d736d14-bf72-4890-bc34-e4790a8ed146"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10217"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "del translator\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5y-muDPy61Iw"
      },
      "outputs": [],
      "source": [
        "summarizer = pipeline(task=\"summarization\",\n",
        "                      model=\"facebook/bart-large-cnn\",\n",
        "                      torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pkvqQNEb631p"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Indian history is a tapestry of diverse cultures, religions, and\n",
        "civilizations that have thrived on the Indian subcontinent for thousands of years.\n",
        "From the ancient civilizations of the Indus Valley and Vedic period to the Maurya and\n",
        "Gupta empires, India has been home to numerous great empires, dynasties, and cultures\n",
        "that have left a profound impact on its history. The country has been a cradle of major\n",
        "religions such as Hinduism, Buddhism, Jainism, and Sikhism, each contributing to its rich\n",
        "cultural heritage. India has also been a melting pot of cultures, with influences from\n",
        "Central Asia, Persia, and Europe shaping its history. The Mughal Empire, known for its\n",
        "architectural marvels and cultural synthesis, and the British colonial rule, which\n",
        "significantly shaped modern India, are key chapters in its history. Today, India stands\n",
        "as a vibrant democracy and a testament to its rich history and cultural diversity.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bATor7go9YQq"
      },
      "source": [
        "To summarize the above paragraph just pass the text into the summarizer pipeline and set the minimum and maximum length of the summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "lAGOZHQv7Hsk"
      },
      "outputs": [],
      "source": [
        "summary = summarizer(text,\n",
        "                     min_length=10,\n",
        "                     max_length=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx6UGJCf7KXK",
        "outputId": "3a848201-87d0-4e35-bb13-e1c3d8c88a16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': 'Indian history is a tapestry of diverse cultures, religions, andcivilizations that have thrived on the Indian subcontinent for thousands of years. The country has been a cradle of major majorreligions such as Hinduism, Buddhism, Jainism, and Sikhism. India has also been a melting pot of cultures, with influences from Central Asia, Persia, and Europe shaping its history.'}]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQziuGsY7K18",
        "outputId": "b1cc6d6d-dbed-491c-bd04-480168809ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.26.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.110.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.15.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "j_84ZF2J7uUi",
        "outputId": "67a58a69-b933-44c8-ab84-47f7397c8c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ca1dd447b276db3241.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ca1dd447b276db3241.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message_list = []\n",
        "response_list = []\n",
        "\n",
        "def chatbot(message, history):\n",
        "    conversation = chatbot(message)\n",
        "\n",
        "    return conversation[0]['generated_text']\n",
        "\n",
        "demo_chatbot = gr.ChatInterface(chatbot, title=\"Chatbot\", description=\"Enter text to start chatting.\")\n",
        "\n",
        "demo_chatbot.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "R1x9mCPO755W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
