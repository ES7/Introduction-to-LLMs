{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Build a ChatBot pipeline Using Hugging Face Transformers Library"
      ],
      "metadata": {
        "id": "M_0EAtT55CLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the transformers library and import the pipeline method to use the open source models also add an additional library to avoid warnings message."
      ],
      "metadata": {
        "id": "d8yLdPtP5MGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip intall transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH2seTTM4zs3",
        "outputId": "bfb7fd87-4f0a-476b-8455-ab3551c30ae2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers.utils import logging\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "YlE9VrR74zvf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the conversation pipeline. The **pipeline()** method in the Transformers library is used to create a simple pipeline for executing a sequence of tasks. First you need to specify the task and then the model you want to use. When you call pipeline() with these parameters, it creates a pipeline object that you can use to analyze text and perform sentiment analysis using the specified model."
      ],
      "metadata": {
        "id": "LaduyiRA5KCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = pipeline(task=\"conversational\",\n",
        "                   model=\"facebook/blenderbot-400M-distill\")"
      ],
      "metadata": {
        "id": "-PS2bFSb4zx_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Info about ['blenderbot-400M-distill'](https://huggingface.co/facebook/blenderbot-400M-distill)"
      ],
      "metadata": {
        "id": "1A1krGZ85lvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"\"\"\n",
        "Suggest me some good project ideas on machine learning?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IvLJ9RWM4z0P"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Conversation"
      ],
      "metadata": {
        "id": "t4hA7K8Z5ucr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = Conversation(user_message)"
      ],
      "metadata": {
        "id": "RvXkZ6Gd5w3b"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3pCS1MN5xBw",
        "outputId": "7d7ec940-e3fa-4f93-eb4b-8b2f871445d3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = chatbot(conversation)"
      ],
      "metadata": {
        "id": "oVdeBFmE5yDA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEzZYHqu50gi",
        "outputId": "c8796a76-2498-49bd-d193-e1b0beedb781"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "assistant:  I'm not sure, but I do know that machines are used in many fields of science and technology.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can continue the conversation with the chatbot with:\n",
        "```\n",
        "print(chatbot(Conversation(\"What else do you recommend?\")))\n",
        "```\n",
        "- However, the chatbot may provide an unrelated response because it does not have memory of any prior conversations.\n",
        "\n",
        "- To include prior conversations in the LLM's context, you can add a 'message' to include the previous chat history."
      ],
      "metadata": {
        "id": "dfvqu1zH5408"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.add_message(\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"\"\"\n",
        "What else do you recommend?\n",
        "\"\"\"\n",
        "    })"
      ],
      "metadata": {
        "id": "kOXHMbaM58uQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTWAkqWT6AU2",
        "outputId": "740fc683-5926-4286-f486-0226440a6699"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "assistant:  I'm not sure, but I do know that machines are used in many fields of science and technology.\n",
            "user: \n",
            "What else do you recommend?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = chatbot(conversation)\n",
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5wz-90G6BUg",
        "outputId": "71e2b69f-7ec1-4618-8bf1-763785002d45"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: eb7c0de9-f29a-412f-b8b2-af3eb8055eb6\n",
            "user: \n",
            "Suggest me some good project ideas on machine learning?\n",
            "\n",
            "assistant:  I'm not sure, but I do know that machines are used in many fields of science and technology.\n",
            "user: \n",
            "What else do you recommend?\n",
            "\n",
            "assistant:  Well, I know that there are many different types of machines that can be used. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
        "- [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)"
      ],
      "metadata": {
        "id": "D4neJjYD6JHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Translation and Summarization"
      ],
      "metadata": {
        "id": "Cay_63c86N5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "fPKJ42bI6CYO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(task=\"translation\",\n",
        "                      model=\"facebook/nllb-200-distilled-600M\",\n",
        "                      torch_dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "NRLeedp56Xua"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLLB: No Language Left Behind: ['nllb-200-distilled-600M'](https://huggingface.co/facebook/nllb-200-distilled-600M). <br>\n",
        "This model is capable of translating 200 languages. By setting the dtype to BFloat16 we are able to compress the model without any performance degradation."
      ],
      "metadata": {
        "id": "4UzA2h0n6bg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\\\n",
        "My pet is adorable, \\\n",
        "Your pet is cute.\n",
        "Her pet is friendly.\n",
        "His pet is thoughtful. \\\n",
        "We all have nice pets!\"\"\""
      ],
      "metadata": {
        "id": "8ondz0B76Z3s"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating the pipeline object we can pass the text that we want to translate and we can set the source language (here english) and the language in which we want the translation (here french)."
      ],
      "metadata": {
        "id": "-cDIUqZ984fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_translated = translator(text,\n",
        "                             src_lang=\"eng_Latn\",\n",
        "                             tgt_lang=\"fra_Latn\")"
      ],
      "metadata": {
        "id": "hE-Fz2Ha6iU7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To choose other languages, you can find the other language codes on the page: [Languages in FLORES-200](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n",
        "\n",
        "For example:\n",
        "- Afrikaans: afr_Latn\n",
        "- Chinese: zho_Hans\n",
        "- Egyptian Arabic: arz_Arab\n",
        "- French: fra_Latn\n",
        "- German: deu_Latn\n",
        "- Greek: ell_Grek\n",
        "- Hindi: hin_Deva\n",
        "- Indonesian: ind_Latn\n",
        "- Italian: ita_Latn\n",
        "- Japanese: jpn_Jpan\n",
        "- Korean: kor_Hang\n",
        "- Persian: pes_Arab\n",
        "- Portuguese: por_Latn\n",
        "- Russian: rus_Cyrl\n",
        "- Spanish: spa_Latn\n",
        "- Swahili: swh_Latn\n",
        "- Thai: tha_Thai\n",
        "- Turkish: tur_Latn\n",
        "- Vietnamese: vie_Latn\n",
        "- Zulu: zul_Latn"
      ],
      "metadata": {
        "id": "K0IbIjKU6myb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2ObFLt36k_U",
        "outputId": "53f97e89-f214-4f22-efd0-43f94c1fed57"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Mon animal est adorable, ton animal est mignon, son animal est ami, son animal est attentionn√©, nous avons tous de beaux animaux.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Free up some space\n",
        "In order to have enough free memory to run the rest of the code, please run the following to free up memory on the machine."
      ],
      "metadata": {
        "id": "6WifcoTQ6qHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del translator\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKI9mJjw6oaC",
        "outputId": "8d736d14-bf72-4890-bc34-e4790a8ed146"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10217"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(task=\"summarization\",\n",
        "                      model=\"facebook/bart-large-cnn\",\n",
        "                      torch_dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "5y-muDPy61Iw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Indian history is a tapestry of diverse cultures, religions, and\n",
        "civilizations that have thrived on the Indian subcontinent for thousands of years.\n",
        "From the ancient civilizations of the Indus Valley and Vedic period to the Maurya and\n",
        "Gupta empires, India has been home to numerous great empires, dynasties, and cultures\n",
        "that have left a profound impact on its history. The country has been a cradle of major\n",
        "religions such as Hinduism, Buddhism, Jainism, and Sikhism, each contributing to its rich\n",
        "cultural heritage. India has also been a melting pot of cultures, with influences from\n",
        "Central Asia, Persia, and Europe shaping its history. The Mughal Empire, known for its\n",
        "architectural marvels and cultural synthesis, and the British colonial rule, which\n",
        "significantly shaped modern India, are key chapters in its history. Today, India stands\n",
        "as a vibrant democracy and a testament to its rich history and cultural diversity.\"\"\""
      ],
      "metadata": {
        "id": "pkvqQNEb631p"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize the above paragraph just pass the text into the summarizer pipeline and set the minimum and maximum length of the summary."
      ],
      "metadata": {
        "id": "bATor7go9YQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarizer(text,\n",
        "                     min_length=10,\n",
        "                     max_length=100)"
      ],
      "metadata": {
        "id": "lAGOZHQv7Hsk"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx6UGJCf7KXK",
        "outputId": "3a848201-87d0-4e35-bb13-e1c3d8c88a16"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'Indian history is a tapestry of diverse cultures, religions, andcivilizations that have thrived on the Indian subcontinent for thousands of years. The country has been a cradle of major majorreligions such as Hinduism, Buddhism, Jainism, and Sikhism. India has also been a melting pot of cultures, with influences from Central Asia, Persia, and Europe shaping its history.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQziuGsY7K18",
        "outputId": "b1cc6d6d-dbed-491c-bd04-480168809ee1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.26.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.110.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.15.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_list = []\n",
        "response_list = []\n",
        "\n",
        "def chatbot(message, history):\n",
        "    conversation = chatbot(message)\n",
        "\n",
        "    return conversation[0]['generated_text']\n",
        "\n",
        "demo_chatbot = gr.ChatInterface(chatbot, title=\"Chatbot\", description=\"Enter text to start chatting.\")\n",
        "\n",
        "demo_chatbot.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "j_84ZF2J7uUi",
        "outputId": "67a58a69-b933-44c8-ab84-47f7397c8c65"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ca1dd447b276db3241.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ca1dd447b276db3241.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R1x9mCPO755W"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}